{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EduardMozharov/ML/blob/main/Project_Emotion_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-rtcvZC8QG4"
      },
      "source": [
        "#Project \"Emotion Detection\"\n",
        "Итоговая работа курса SKILLBOX:  \n",
        "Data Science. ML. Средний уровень (Нейронны сети))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGJ7TyGF7J-V"
      },
      "source": [
        "# Задание\n",
        "**Цель** - реализовать нейронную сеть, распознающую эмоции\n",
        "\n",
        "**Задачи:**\n",
        "1. Работа требует реализации алгоритма, с помощью которого будет происходить заданная классификация. Приветствуется использование архитектур свёрточных нейронных сетей, разобранных во время теоретических занятий. Время инференса сети на Google Colab не должно превышать 0,33 секунды (3 кадра в секунду).\n",
        "\n",
        "2. Создать скрипт, который будет работать с их веб-камерами и выводить на экран текущую эмоцию.\n",
        "\n",
        "\n",
        "**Дополнительно:**  \n",
        "1. Используйте подходы по искусственному увеличению датасета для обучения, а именно — аргументации, рассмотренные в курсе.\n",
        "2. Используйте продвинутые техники обучения, такие как finetuning и другие, рассмотренные в курсе.\n",
        "3. Пишите структурный код (основная логика кода должна быть вынесена в классы/методы/функции + осмысленный нейминг сущностей и комментарии).\n",
        "4. Проведите эксперименты с valence-arousal разложением эмоций, когда модель обучается не на самих эмоциях, а на их разложении по этим двум компонентам. Информация о подобном разложении есть в дополнительных материалах.\n",
        "\n",
        " \n",
        "Работающий прототип из пункта «Улучшение и дополнения к заданию» прибавляет один балл к итоговой оценке и добавляет в портфолио ценный ML-проект.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1l-0ga0dVuO"
      },
      "source": [
        "## Отправка результата на проверку\n",
        "Метрика данного соревнования categorisation accuracy.\n",
        "\n",
        "Формат решения\n",
        "Для каждого изображения в тестовом датасете, файл с решением должен содержать две колонки: image_path и emotion. image_path -- название изображение. Имеет формат k.jpg, где k натуральное число от 0 до 4999. emotion -- название предсказанной эмоции для данного изображение. Все представленные в задании эмоции вы можете найти на странице с описанием данных.\n",
        "\n",
        "Итоговый csv файл должен иметь названия колонок и иметь структуру, как представлено ниже\n",
        "\n",
        "image_path,emotion  \n",
        "0.jpg,neutral  \n",
        "1.jpg,angry  \n",
        "2.jpg,sad  \n",
        "3.jpg,contempt  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFYqw13S8N6S"
      },
      "source": [
        "# 1 Загрузим необходимые библиотеки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_GpsIZFfNN1h"
      },
      "outputs": [],
      "source": [
        "DO_IT = False # Выполнять ли особые части кода"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HgV-Yz4LDJRe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4ab6fdd-9936-443b-968e-60e1a4b5faa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting livelossplot\n",
            "  Downloading livelossplot-0.5.5-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from livelossplot) (3.7.1)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.9/dist-packages (from livelossplot) (2.4.3)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.9/dist-packages (from bokeh->livelossplot) (6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0 in /usr/local/lib/python3.9/dist-packages (from bokeh->livelossplot) (4.5.0)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.9/dist-packages (from bokeh->livelossplot) (8.4.0)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.9/dist-packages (from bokeh->livelossplot) (23.0)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.9/dist-packages (from bokeh->livelossplot) (3.1.2)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.9/dist-packages (from bokeh->livelossplot) (1.22.4)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.9/dist-packages (from bokeh->livelossplot) (6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->livelossplot) (1.0.7)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->livelossplot) (5.12.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->livelossplot) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->livelossplot) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->livelossplot) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->livelossplot) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->livelossplot) (4.39.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->livelossplot) (3.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from Jinja2>=2.9->bokeh->livelossplot) (2.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib->livelossplot) (1.16.0)\n",
            "Installing collected packages: livelossplot\n",
            "Successfully installed livelossplot-0.5.5\n"
          ]
        }
      ],
      "source": [
        "!pip install livelossplot\n",
        "\n",
        "# Для работы оптимизатора TensorRT может потребоваться предыдущая версия tensorflow\n",
        "#!pip install -U tensorflow==2.7.0\n",
        "#!pip install keras==2.6.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjdfMLtG7Fbq",
        "outputId": "e69be355-328c-4da7-9864-2885646b9241"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.11.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import random\n",
        "\n",
        "import tensorflow as tf\n",
        "print('TensorFlow version:', tf.__version__)\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from livelossplot.tf_keras  import PlotLossesCallback\n",
        "\n",
        "import timeit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_mOHFyMFHi6"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ry-ZzkcCDEz0"
      },
      "source": [
        "#2. Загрузим данные и рассмотрим их"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IIJnMrPGlbh"
      },
      "source": [
        "## 2.1 Загрузим рисунки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0fDDmOa7Fe1",
        "outputId": "a3b739a0-ca8b-466f-d974-e63390900a01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ySo-LjBxIEuP"
      },
      "outputs": [],
      "source": [
        "# Один раз загрузим и разархивируем данные на личный диск,\n",
        "# чтобы каждый раз заново не загружать данные\n",
        "path = '/content/drive/MyDrive/SKILLBOX/FinalWorks/ML/'\n",
        "#os.chdir(path)\n",
        "#!unzip -q train.zip\n",
        "#!unzip -q test_kaggle.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5cRRadcGtXU"
      },
      "source": [
        "## 2.2. Загрузим табличные данные и рассмотрим их"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "bNQYE2-pJkLx",
        "outputId": "a0fea743-3a7e-44a8-8595-c26ea5177eec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество строк данных 50046\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0              image_path emotion\n",
              "0           0     ./train/anger/0.jpg   anger\n",
              "1           1     ./train/anger/1.jpg   anger\n",
              "2           2    ./train/anger/10.jpg   anger\n",
              "3           3   ./train/anger/100.jpg   anger\n",
              "4           4  ./train/anger/1000.jpg   anger"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-41b73c38-fe1f-4b48-8da5-b042c55bf718\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>image_path</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>./train/anger/0.jpg</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>./train/anger/1.jpg</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>./train/anger/10.jpg</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>./train/anger/100.jpg</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>./train/anger/1000.jpg</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-41b73c38-fe1f-4b48-8da5-b042c55bf718')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-41b73c38-fe1f-4b48-8da5-b042c55bf718 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-41b73c38-fe1f-4b48-8da5-b042c55bf718');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Загрузим таблицу с описанием данных train\n",
        "df = pd.read_csv(path+'train.csv')\n",
        "n_data = df.shape[0]\n",
        "print('Количество строк данных', n_data)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd4_uq3fGMxS",
        "outputId": "0898eb97-fee3-411b-8034-42c460bcd83c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Всего эмоций 9: ['anger' 'contempt' 'disgust' 'fear' 'happy' 'neutral' 'sad' 'surprise'\n",
            " 'uncertain'] \n"
          ]
        }
      ],
      "source": [
        "emotions = df.emotion.unique()\n",
        "n_emotions = emotions.shape[0]\n",
        "\n",
        "print(\"Всего эмоций {}: {} \".format(n_emotions, emotions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tGSh7qfG7SH"
      },
      "source": [
        "**image_path** - строка, являющаюся путем до изображения в случае обучения или названием изображения в случае теста  \n",
        "**emotion** - строка, характеризующая эмоцию  \n",
        "\n",
        "  \n",
        "В данном задании требуется предсказать 9 базовых эмоций, таких как:  \n",
        "* **neutral** - нейтральная эмоция\n",
        "* **anger**- гнев, злость\n",
        "* **contempt** - презрение\n",
        "* **disgust** - отвращение\n",
        "* **fear** - страх\n",
        "* **happy** - веселый\n",
        "* **sad** - грусть\n",
        "* **surprise** - удивленность\n",
        "* **uncertain** - неуверенность"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oa2hdPBUIBqF",
        "outputId": "b95c8284-1737-4b92-83d6-4ca0a68e4018"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "emotion\n",
              "anger        7022\n",
              "contempt     3085\n",
              "disgust      3155\n",
              "fear         5044\n",
              "happy        5955\n",
              "neutral      6795\n",
              "sad          6740\n",
              "surprise     6323\n",
              "uncertain    5927\n",
              "Name: image_path, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df_count = df.groupby('emotion').count()['image_path']\n",
        "df_count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVbrtcdmHj6h"
      },
      "source": [
        "## 2.3 Рассмотрим рисунки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUc6rnpVHogt"
      },
      "outputs": [],
      "source": [
        "def show_img(img_ind=1):\n",
        "  img = plt.imread(path+df['image_path'][img_ind][2:])\n",
        "  plt.imshow(img)\n",
        "  plt.title(df['emotion'][img_ind])\n",
        "\n",
        "def show_random_test_img(n_img=10):\n",
        "    plt.figure(figsize=(20,10))\n",
        "    for i in range(n_img):\n",
        "        plt.subplot(4,8, i+1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.grid(False)\n",
        "        img_ind = random.randint(0, n_data)\n",
        "        show_img(img_ind)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKeKam6PKFIi"
      },
      "outputs": [],
      "source": [
        "if DO_IT: \n",
        "  show_img(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-BGVBRPwxJa"
      },
      "outputs": [],
      "source": [
        "if DO_IT:\n",
        "  show_random_test_img(n_img=16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XFTNdovoKr2"
      },
      "source": [
        "# 3. Рассмотрим тестовые данные"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "NsJocm50cNng",
        "outputId": "731f82cf-c58f-462d-e649-87a9d1b9b0ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nget_files = os.listdir(path_test)\\nfor g in get_files:\\n  if g != '1':\\n    os.replace(path_test + g, path_test_new + g)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "path_test = path + 'test_kaggle/'    # Путь к тестовым изображениям\n",
        "path_test_new = path_test + '1/'  # Путь, куда переместим данные\n",
        " \n",
        "'''\n",
        "get_files = os.listdir(path_test)\n",
        "for g in get_files:\n",
        "  if g != '1':\n",
        "    os.replace(path_test + g, path_test_new + g)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dav7JgTOoeoQ"
      },
      "outputs": [],
      "source": [
        "def show_test_img(n_img=0):\n",
        "  img = plt.imread(path_test_new + str(n_img) + '.jpg')\n",
        "  plt.imshow(img)\n",
        "\n",
        "if DO_IT:\n",
        "  show_test_img(n_img=1)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9RfjZxWwx3Q"
      },
      "source": [
        "# 4. Подготовка данных. Аугментация.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_oOAgSfBxW40"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128\n",
        "IMG_SHAPE  = 64\n",
        "VAL_PART = 0.2    # Размер валидационной выборки от исходных данных \n",
        "RANDOM_STATE = 17"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEvMksNjoglM"
      },
      "source": [
        "## 4.1 Разобью выборку на обучающую и валидационную"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3m20L_14f30"
      },
      "outputs": [],
      "source": [
        "df['img_path_new'] = df['image_path'].apply(lambda x: x[2:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AL2sjR6o85Hr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cc01525-41dc-41d3-d373-79a47d838258"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размер обучающей выборки: 40036\n",
            "Размер валидационной выборки: 10010\n"
          ]
        }
      ],
      "source": [
        "# Перемешаем случайным образом строки и выбирем \n",
        "df_train, df_val = np.split(df.sample(frac=1, random_state=RANDOM_STATE), [int((1-VAL_PART)*len(df))])\n",
        "\n",
        "print('Размер обучающей выборки:', len(df_train))\n",
        "print('Размер валидационной выборки:', len(df_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52ti7pSDyBBj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b335f04f-3a03-452f-e0d2-253309bc1989"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emotion\n",
            "anger        5627\n",
            "contempt     2468\n",
            "disgust      2562\n",
            "fear         3940\n",
            "happy        4745\n",
            "neutral      5476\n",
            "sad          5377\n",
            "surprise     5064\n",
            "uncertain    4777\n",
            "Name: image_path, dtype: int64\n",
            "-------------------\n",
            "emotion\n",
            "anger        1395\n",
            "contempt      617\n",
            "disgust       593\n",
            "fear         1104\n",
            "happy        1210\n",
            "neutral      1319\n",
            "sad          1363\n",
            "surprise     1259\n",
            "uncertain    1150\n",
            "Name: image_path, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Проверим, что попали разные эмоции в каждую из выборок\n",
        "print(df_train.groupby('emotion').count()['image_path'])\n",
        "print('-------------------')\n",
        "print(df_val.groupby('emotion').count()['image_path'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNgYsOPss2pb"
      },
      "source": [
        "## 4.2 Выполним Аугментацию данных и создадим генераторы данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7OZ8dTQzCa7"
      },
      "outputs": [],
      "source": [
        "# Выполним Аугментацию\n",
        "train_image_generator = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=10,  # максимальный угол поворота\n",
        "      width_shift_range=0.2, # смещение максимум на 20% ширины по горизонтали\n",
        "      height_shift_range=0.2, # смещение максимум на 20% высоты по вертикали\n",
        "      zoom_range=0.2, # картинка будет увеличена или уменьшена не более чем на 20% \n",
        "      horizontal_flip=False, # случайное отражение по горизонтали\n",
        "      vertical_flip=False, # случайное отражение по вертикали\n",
        "      fill_mode=\"nearest\", # чем заполнять пробелы -- сначала выберем черный цвет, а потом изменим на \"nearest\"\n",
        "      #cval=0,\n",
        "      ) \n",
        "\n",
        "val_image_generator = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=10,  # максимальный угол поворота\n",
        "      width_shift_range=0.2, # смещение максимум на 20% ширины по горизонтали\n",
        "      height_shift_range=0.2, # смещение максимум на 20% высоты по вертикали\n",
        "      zoom_range=0.2, # картинка будет увеличена или уменьшена не более чем на 20% \n",
        "      horizontal_flip=False, # случайное отражение по горизонтали\n",
        "      vertical_flip=False, # случайное отражение по вертикали\n",
        "      fill_mode=\"nearest\", # чем заполнять пробелы -- сначала выберем черный цвет, а потом изменим на \"nearest\"\n",
        "      #cval=0,\n",
        "      ) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLJ7Paj2w3fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ea36fd6-aafe-4d18-8a35-ecaff70d1de6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 40036 validated image filenames belonging to 9 classes.\n",
            "CPU times: user 2.38 s, sys: 2.57 s, total: 4.95 s\n",
            "Wall time: 4min 16s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Создадим генератор на основе тренировочных данных\n",
        "train_data_gen = train_image_generator.flow_from_dataframe(df_train, directory=path,\n",
        "                                                           x_col='img_path_new', y_col='emotion',\n",
        "                                                           batch_size=BATCH_SIZE,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_SHAPE,IMG_SHAPE), \n",
        "                                                           class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0EeXegEQiy0y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11f44044-3656-4282-a97c-e90697d0eec4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10010 validated image filenames belonging to 9 classes.\n"
          ]
        }
      ],
      "source": [
        "# Создадим генератор на основе валидационных данных\n",
        "val_data_gen = val_image_generator.flow_from_dataframe(df_val, directory=path,\n",
        "                                                           x_col='img_path_new', y_col='emotion',\n",
        "                                                           batch_size=BATCH_SIZE,\n",
        "                                                           shuffle=False,\n",
        "                                                           target_size=(IMG_SHAPE,IMG_SHAPE), \n",
        "                                                           class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSKjRLnoxoda"
      },
      "outputs": [],
      "source": [
        "def show_faces(images, labels, predicted_labels=None, emotions=emotions):\n",
        "  # Демонстрирует изображения с подписями, и при наличии - их предсказаниями\n",
        "    plt.figure(figsize=(20,10))\n",
        "    for i in range(32):\n",
        "        plt.subplot(4,8, i+1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.grid(False)\n",
        "        plt.imshow(images[i], cmap=plt.cm.gray)\n",
        "        if predicted_labels is not None:\n",
        "            title_obj = plt.title(f\"Real: {emotions[labels[i]]}. Pred: {emotions[np.argmax(predicted_labels[i])]}\")\n",
        "            if labels[i] != predicted_labels[i]:\n",
        "                plt.setp(title_obj, color='r')\n",
        "        else:\n",
        "            plt.title(f\"Real label: {emotions[np.argmax(labels[i])]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjezyF0JNazN"
      },
      "outputs": [],
      "source": [
        "#Посмотрим, что выдает генератор тренеровочных данных\n",
        "if DO_IT:\n",
        "  example_32_img = train_data_gen.next()[:32]\n",
        "  show_faces(example_32_img[0], example_32_img[1], predicted_labels=None, emotions=emotions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hg_Jy99XDZ24"
      },
      "source": [
        "#5. Модель #1 - небольшая классическая сверточная нейронная сеть (CNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efyS1Ka4FQms"
      },
      "source": [
        "В ходе выполнения работы придерживаемся следующих правил по оптимизации времения выполнения сети:\n",
        "1) Оптимизация модели при обучении:\n",
        "   * 1.1)  От простой модели к сложной.\n",
        "   * 1.2) Не заставлять учить то, что задается явно.\n",
        "   * 1.3) Понизить ширину сети за счет Conv(1х1).\n",
        "   * 1.4) Заменить Conv+Pool2D на Strided Conv.\n",
        "   * 1.5) Использовать активацию Relu по возможности.\n",
        "   * 1.6) Количество карт признаков делать кратным 8.\n",
        "   * 1.7) Применить поканальную сепарабельную свертку (Depth-wise separable Conv).\n",
        "   * 1.8) Применить Прореживание (Puring).\n",
        "   * 1.9) Другое... \n",
        "\n",
        "2) Оптимизация модели после обучения: с помощью TensorRT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7Sflvsp7Fmy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fd0c27d-97b8-4e53-8062-82560908d301"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 8192)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               1048704   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 9)                 1161      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,143,113\n",
            "Trainable params: 1,143,113\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_1 = tf.keras.Sequential()\n",
        "model_1 .add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3),\n",
        "                                 padding='same', activation='relu',\n",
        "                                 input_shape=(IMG_SHAPE,IMG_SHAPE,3),\n",
        "                                 strides=(2,2)))\n",
        "model_1 .add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3),\n",
        "                                 padding='same', activation='relu',\n",
        "                                 strides=(2,2)))\n",
        "model_1 .add(tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3),\n",
        "                                 padding='same', activation='relu',\n",
        "                                 strides=(2,2)))\n",
        "model_1 .add(tf.keras.layers.Flatten())\n",
        "model_1 .add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model_1 .add(tf.keras.layers.Dense(n_emotions, activation='softmax'))\n",
        "model_1.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fWKQoK0E5e-"
      },
      "source": [
        "##5.1 Проверим время работы одного прохода нейронной сети"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRPmyw7kE9NS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92208ffa-bf55-4857-cdf5-e987ea04b947"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The slowest run took 5.67 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "7.16 ms ± 6.3 ms per loop (mean ± std. dev. of 10 runs, 10 loops each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit -n 10 -r 10\n",
        "q_opt = model_1(np.random.rand(1, IMG_SHAPE, IMG_SHAPE, 3).astype(np.float32))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZBjOklbDjjN"
      },
      "source": [
        "## 5.2. Обучение модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyHXzmxDY_vj"
      },
      "outputs": [],
      "source": [
        "# Скомпилируем модель\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "model_1.compile(optimizer=optimizer,\n",
        "              loss=loss,\n",
        "              metrics=['accuracy', 'categorical_accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "             filepath= path + 'saved_models/model_1_checkpoint',\n",
        "             monitor='accuracy', verbose=1, save_best_only=True,\n",
        "             mode='max')"
      ],
      "metadata": {
        "id": "EBJJNRsnA5pV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxvp4MIqDn01"
      },
      "outputs": [],
      "source": [
        "# Обучим модель\n",
        "EPOCHS = 40\n",
        "STEPS_PER_EPOCH = 64\n",
        "\n",
        "history = model_1.fit(\n",
        "    train_data_gen,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_data_gen,\n",
        "    steps_per_epoch = STEPS_PER_EPOCH,\n",
        "    shuffle = True,\n",
        "#    validation_freq=[10, 20, 30, EPOCHS],\n",
        "    callbacks=[PlotLossesCallback(), checkpoint]) # мы добавили коллбек для отрисовки прогресса"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXNBKVAsbyJh"
      },
      "source": [
        "##5.3 Сохраним модель"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name_saved_model = 'saved_models/model_1/model_1_epochs_160'"
      ],
      "metadata": {
        "id": "WLTbN8ybAA23"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZzZbxNGy6mlh"
      },
      "outputs": [],
      "source": [
        "model_1.save(path + name_saved_model)\n",
        "# Сохраним историю\n",
        "cat_acc = pd.DataFrame(history.history['categorical_accuracy'])\n",
        "cat_acc.to_csv(path + name_saved_model + 'cat_acc.csv')\n",
        "val_cat_acc = pd.DataFrame(history.history['val_categorical_accuracy'])\n",
        "val_cat_acc.to_csv(path + name_saved_model + 'cat_val_acc.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHAlORcwCI47"
      },
      "source": [
        "##5.4 Загрузка модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E74T8d7qCOxG"
      },
      "outputs": [],
      "source": [
        "model_1 = tf.keras.models.load_model(path + 'saved_models/model_1_epochs_120')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.5 Отобразим процесс обучения"
      ],
      "metadata": {
        "id": "mGqN8chY_oP3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "zBJxqB_NAUNf",
        "outputId": "532fc84f-f4ab-4068-d835-f194824c976e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   epoch   cat_acc\n",
              "0      0  0.135620\n",
              "1      1  0.143311\n",
              "2      2  0.151367\n",
              "3      3  0.153564\n",
              "4      4  0.157104\n",
              "5      5  0.173689\n",
              "6      6  0.178223\n",
              "7      7  0.181396\n",
              "8      8  0.191772\n",
              "9      9  0.192185"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4a3f6a8a-5018-465f-bc00-be692e6fe2e0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epoch</th>\n",
              "      <th>cat_acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.135620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.143311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.151367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.153564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.157104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>0.173689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>0.178223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>0.181396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>0.191772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>0.192185</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a3f6a8a-5018-465f-bc00-be692e6fe2e0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4a3f6a8a-5018-465f-bc00-be692e6fe2e0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4a3f6a8a-5018-465f-bc00-be692e6fe2e0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_val = pd.read_csv(csv_path + 'cat_val_acc.csv',names=['epoch','cat_val_acc'], skiprows=1)\n",
        "df_val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "pnQXaqVbHCo6",
        "outputId": "7fc3e46e-0751-4ecb-e2bf-f2445ab45650"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   epoch  cat_val_acc\n",
              "0      0     0.146753\n",
              "1      1     0.192607"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3c5ac41b-65af-44b2-8988-cfd04b0dbb8a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epoch</th>\n",
              "      <th>cat_val_acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.146753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.192607</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c5ac41b-65af-44b2-8988-cfd04b0dbb8a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3c5ac41b-65af-44b2-8988-cfd04b0dbb8a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3c5ac41b-65af-44b2-8988-cfd04b0dbb8a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_acc= []\n",
        "cat_acc, cat_val =  [], []\n",
        "epochs_steps = [10, 20, 30, 40, 50, 80, 120]\n",
        "\n",
        "for i in range(len(epochs_steps)):\n",
        "  csv_path = path + 'saved_models/model_1/model_1_epochs_' + str(epochs_steps[i]) \n",
        "  df_acc = pd.read_csv(csv_path + 'cat_acc.csv',names=['epoch','cat_acc'], skiprows=1)\n",
        "  df_val = pd.read_csv(csv_path + 'cat_val_acc.csv',names=['epoch','cat_val_acc'], skiprows=1)\n",
        "  \n",
        "  if i == 0:\n",
        "      epochs_acc.extend(list(df_acc['epoch'] + 1))\n",
        "  else:\n",
        "      epochs_acc.extend(list(df_acc['epoch'] + 1 + epochs_steps[i-1]))\n",
        "\n",
        "  cat_acc.extend(list(df_acc['cat_acc']))\n",
        "  cat_val.append(list(df_val['cat_val_acc'])[-1])\n",
        "\n",
        "plt.plot(epochs_acc, cat_acc)\n",
        "plt.plot(epochs_steps, cat_val)\n",
        "plt.xlabel('Номер Эпохи')\n",
        "plt.ylabel('Categorical_accuracy')\n",
        "plt.legend(['Train', 'Val'])\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "c5TvXslb_t_p",
        "outputId": "7f367a88-9814-44e3-b4bd-e733b0a941aa"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoV_-tVCozBx"
      },
      "source": [
        "##5.6 Выполним предсказания на тестовых данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rFMJjALr-V7j"
      },
      "outputs": [],
      "source": [
        "# Создадим генератор, выдающий преобразованные тестовые данные\n",
        "test_image_generator = ImageDataGenerator(rescale=1./255)\n",
        "test_data_gen = test_image_generator.flow_from_directory(directory=path_test,\n",
        "                                                         batch_size=BATCH_SIZE,\n",
        "                                                         shuffle=False,\n",
        "                                                         target_size=(IMG_SHAPE,IMG_SHAPE),\n",
        "                                                         class_mode=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZbFQVIiA_rhp"
      },
      "outputs": [],
      "source": [
        "# Функция генерирования csv файла с предсказаниями\n",
        "def generate_prediction_csv(model, test_data_gen, name_of_file):\n",
        "  ''' Функция генерирования csv файла с предсказаниями'''\n",
        "  N = len(os.listdir(path_test_new))    # Количество тестовых рисунков\n",
        "  filenames = test_data_gen.filenames   # Имена файлов генератора\n",
        "  filenames = [filenames[i][2:] for i in range(N)]\n",
        "\n",
        "  pred = model.predict(test_data_gen, batch_size=BATCH_SIZE) # Предсказания\n",
        "  dict_pred = {'image_path':  filenames, 'emotion': emotions[np.argmax(pred, axis=1)]}    # Создаем словарь\n",
        "  df = pd.DataFrame(data=dict_pred)\n",
        "  # Отсортируем по порядку численному имена файлов\n",
        "  df['num'] = [int(x[:-4]) for x in df['image_path']]\n",
        "  df_pred = df.sort_values(by='num')[['image_path','emotion']]\n",
        "  df_pred.to_csv(name_of_file + '.csv', sep=',', index=False)\n",
        "  return df_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CDvNRgxQ-nmN"
      },
      "outputs": [],
      "source": [
        "# Другой способ реализации Функции генерирования csv файла с предсказаниями\n",
        "'''\n",
        "def generate_prediction_csv(model, path_test, IMG_SHAPE, name_of_file):\n",
        "  # Функция генерирования csv файла с предсказаниями\n",
        "  N = len(os.listdir(path_test_new))\n",
        "  pred = {}\n",
        "  for i in range(N):\n",
        "    name = str(i) + '.jpg'\n",
        "    img = plt.imread(path_test + name)\n",
        "    img_mod = tf.image.resize(img, (IMG_SHAPE, IMG_SHAPE), tf.image.ResizeMethod.BILINEAR)\n",
        "    img_mod =  img_mod * 1./255\n",
        "    pred[name] = model.predict(img_mod[..., ::-1])\n",
        "\n",
        "  df_pred = pd.DataFrame(pred,columns=['image_path', 'emotion'])\n",
        "  df_pred.to_csv(name_of_file + '.csv', sep=',')\n",
        "  return df_pred\n",
        "'''\n",
        "\n",
        "# Третий способ - создать датафрейм и создать генератор по нему через .flow_from_dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XGbhMqVx_4tE"
      },
      "outputs": [],
      "source": [
        "# Генерирую файл csv с предсказанием\n",
        "%%time\n",
        "df_pred = generate_prediction_csv(model_1, test_data_gen, path+'prediction_model_1_epochs_120')\n",
        "df_pred.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VL_O3HA6hH1"
      },
      "source": [
        "| IMG_SHAPE     | BATCH_SIZE  | EPOHS| Time, hours |   categorical_accuracy  | \n",
        "| ------------- |-------------|-----| ----------------------| ----------------------|\n",
        "|  64           | 128       | 30  | 4 |0.2356| \n",
        "|  64           | 128       | 40  | 5 |0.2532| \n",
        "|  64           | 128       | 60  | 6 |0.3017| \n",
        "|  64           | 128       | 80  | 7 |0.3406| \n",
        "|  64           | 256       | 60  |  |0.| "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45fd5bs0_a0d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmHTLfiC6ntL"
      },
      "source": [
        "# 4. Модель #2 - с применением Fine-Tuning\n",
        "За основу возьмем сеть VGG19, обученную на ImageNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoK-kD1F6l64",
        "outputId": "2241527c-32c0-49e1-eb9f-5c3a57853cbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels.h5\n",
            "574710816/574710816 [==============================] - 4s 0us/step\n",
            "Model: \"vgg19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              102764544 \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 4096)              16781312  \n",
            "                                                                 \n",
            " predictions (Dense)         (None, 1000)              4097000   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 143,667,240\n",
            "Trainable params: 143,667,240\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_vgg19 = tf.keras.applications.VGG19(weights='imagenet')  \n",
        "model_vgg19.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFK7SQbwjIdl",
        "outputId": "7b60e86c-1175-4f13-efee-90f6fcffb3b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Количество слоев в базовой модели:  25\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              102764544 \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 4096)              16781312  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 139,570,240\n",
            "Trainable params: 0\n",
            "Non-trainable params: 139,570,240\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Оставим все слои кроме последнего\n",
        "base_model = tf.keras.Model([model_vgg19.input], model_vgg19.get_layer(\"fc2\").output)\n",
        "print(\"Количество слоев в базовой модели: \", len(base_model.layers))\n",
        "\n",
        "#Разморозим всче слои\n",
        "base_model.trainable =  True\n",
        "\n",
        "fine_tune_at = 25\n",
        "# все слои до fine_tune_at -- заморозим\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "  layer.trainable =  False\n",
        "\n",
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmhrIL0ijIiv",
        "outputId": "9de2a7fd-a5c7-47c7-fbd2-b4ebd9df74da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " model (Functional)          (None, 4096)              139570240 \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 9)                 36873     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 139,607,113\n",
            "Trainable params: 36,873\n",
            "Non-trainable params: 139,570,240\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Добавим выходной слой с n_emotions\n",
        "model_2 = tf.keras.Sequential([\n",
        "           base_model,\n",
        "           tf.keras.layers.Dense(n_emotions, activation='softmax')\n",
        "           ])\n",
        "\n",
        "model_2.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3OsMgrfa3Ur"
      },
      "source": [
        "#4.1 Проверим время работы одного прохода нейронной сети"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8QejzPCau-6",
        "outputId": "41a2ea93-8ad0-4bf1-cba0-5d8c4ec875a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "583 ms ± 45.7 ms per loop (mean ± std. dev. of 10 runs, 10 loops each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit -n 10 -r 10\n",
        "q_opt = model_2(np.random.rand(1, IMG_SHAPE, IMG_SHAPE, 3).astype(np.float32))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaHZU0oybKjt"
      },
      "source": [
        "## 4.2. Дообучение модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ddyBNlVa-6h"
      },
      "outputs": [],
      "source": [
        "# Скомпилируем модель\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "model_2.compile(optimizer=optimizer,\n",
        "              loss=loss,\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHx7GluUa54B"
      },
      "outputs": [],
      "source": [
        "# Обучим модель\n",
        "EPOCHS = 1\n",
        "history = model_2.fit(\n",
        "    train_data_gen,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_data_gen,\n",
        "    callbacks=[PlotLossesCallback()]) # мы добавили коллбек для отрисовки прогресса"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VH56U2M-Fsz2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "IZ3Q1udQFs8z",
        "outputId": "8f1cc63f-0fde-4c01-8e96-7de26381bf16"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-66de02a91eae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Генерирую файл csv с предсказанием\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_prediction_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_test_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'prediction_model_2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-57-0f84367e7182>\u001b[0m in \u001b[0;36mgenerate_prediction_csv\u001b[0;34m(model, path_test, IMG_SHAPE, name_of_file)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_test\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mimg_mod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mIMG_SHAPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_SHAPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResizeMethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBILINEAR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_mod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mdf_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image_path'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'emotion'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_1\" is incompatible with the layer: expected shape=(None, 64, 64, 3), found shape=(32, 224, 3)\n"
          ]
        }
      ],
      "source": [
        "# Генерирую файл csv с предсказанием\n",
        "df_pred = generate_prediction_csv(model_2, path_test_new, 224, 'prediction_model_2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzjWZ26lFIpI"
      },
      "source": [
        "#5. Оптимизация модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0BmUAdcFMQi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qyvObQs2WkN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YL4EfDa2X2p"
      },
      "source": [
        "# 6. Проведите эксперименты с valence-arousal разложением эмоций, когда модель обучается не на самих эмоциях, а на их разложении по этим двум компонентам"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7rePxJ4QiZg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mvHPzV-QkC7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFXAsuyvQlEC"
      },
      "source": [
        "# 7. Определение эмоции по видео с камеры"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdtPYqJ6Qpjz"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "#from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymQNRNAyQ370",
        "outputId": "c490a036-9fd2-4d25-c30e-a9961b380ad1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n"
          ]
        }
      ],
      "source": [
        "cam_port = 0\n",
        "cam = cv2.VideoCapture(cam_port)\n",
        "  \n",
        "# reading the input using the camera\n",
        "result, image = cam.read()\n",
        "print(result)\n",
        "if result:\n",
        "    cv2.imshow(\"GeeksForGeeks\", image)\n",
        "    cv2.waitKey(1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPe+5Dji2CvivNHYA2d0POZ",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}